{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic neural net built with \"make your own neural network\" guidance. \n",
    "\n",
    "I tried to code it myself but in the end, got stuck with a subtle bug that I describe below. It was kind of short-sighted of me; \n",
    "if my original approach were equivalent to the correct approach, training neural nets wouldn't take so long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "\n",
    "#neural network class definition \n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # input number of nodes in each of 3 layers\n",
    "    def __init__(self, ninodes, nhnodes, nonodes, lr):\n",
    "        \n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inodes = ninodes\n",
    "        self.hnodes = nhnodes\n",
    "        self.onodes = nonodes\n",
    "        self.lr = lr\n",
    "        \n",
    "        # initialize matrix with normal random variables \n",
    "        self.wih = np.random.normal(0.0, \n",
    "                                        pow(float(self.hnodes), -0.5),\n",
    "                                        (self.hnodes, self.inodes)\n",
    "                                      )\n",
    "        self.who = np.random.normal(0.0,\n",
    "                                     pow(float(self.onodes), -0.5),\n",
    "                                     (self.onodes, self.hnodes)\n",
    "                                      )\n",
    "        \n",
    "        \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        \n",
    "        # if inputs_list is a list of m items each of length n,\n",
    "        # np.array will turn it into an mxn matrix.\n",
    "        # ie, it will add records row by row.\n",
    "        # the result gets transposed here.\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        \n",
    "        # calculate signals coming out of hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals going into output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # calculate final output\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        \n",
    "        # We will need the output and the hidden layer errors,\n",
    "        # both calculated up front, i.e., before the changes are applied to the interior weights.\n",
    "        # the hidden layer error is equal to the output_errors \n",
    "        # passed backward through the weights between the hidden and output\n",
    "        # layers (transposed).\n",
    "        # note that self.wts_ho.T is num_hidden x num_output,\n",
    "        # so hidden_errors is a num_hidden x 1 vector.\n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        \n",
    "        # now we backpropagate.\n",
    "        # step 1: adjust the hidden->outer weights wts_ho.\n",
    "        # these are components of the gradient of the error function\n",
    "        # wrt the hidden->output weights wts_ho (dimension outer x hidden).\n",
    "        # note that this is an outer product of the \n",
    "        # hidden and output components of the gradient        \n",
    "        self.who += self.lr * np.dot((output_errors*final_outputs*(1.0-final_outputs)), hidden_outputs.T)\n",
    "        \n",
    "        # the next step is the same, shifted to the input->hidden weights.\n",
    "        #hidden_component_of_wts_ih_delta = hidden_errors*hidden_outputs*(1.0-hidden_outputs)\n",
    "        #input_component_of_wts_ih_delta = inputs\n",
    "        \n",
    "        # again, outer product of input and hidden components of the gradient\n",
    "        self.wih += self.lr * np.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)), inputs.T) \n",
    "        \n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def query(self,inputs_list):\n",
    "        inputs = np.array(inputs_list, ndmin =2).T\n",
    "        \n",
    "        # calcualte signals entering hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        \n",
    "        # signals leaving hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # signals entering final layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # signals leaving final layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = NeuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine wasn't working -- it was driving me crazy since the training code was virtually identical. \n",
    "\n",
    "So in the next 4 lines, I duplicated his training and testing code.\n",
    "I eventually figured out the difference -- he was calling train() individually on every new sample, while I was only calling it once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HIS TRAINING & TEST CODE 1\n",
    "training_file = open(\"/mnt/xferUbuntu/notebooks/make_your_own_neural_network/mnist/mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_file.readlines()\n",
    "training_file.close()\n",
    "\n",
    "# load the mnist training data CSV file into a list\n",
    "#training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "#training_data_list = training_data_file.readlines()\n",
    "#training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HIS TRAINING & TEST CODE 2\n",
    "# NOTE HE IS TRAINING INDIVIDUALLY ON EVERY NEW EXAMPLE -- THIS MUST BE THE REASON IT'S WORKING\n",
    "\n",
    "for record in training_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "    targets = np.zeros(output_nodes) + 0.01\n",
    "    # all_values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HIS TRAINING & TEST CODE 3\n",
    "test_file = open(\"/mnt/xferUbuntu/notebooks/make_your_own_neural_network/mnist/mnist_test_10.csv\", 'r')\n",
    "test_data = test_file.readlines()\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The test step below was turning out well for him because he was doing 100 training iterations TO MY ONE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03584036],\n",
       "       [ 0.00353559],\n",
       "       [ 0.04111049],\n",
       "       [ 0.02744567],\n",
       "       [ 0.01407476],\n",
       "       [ 0.03854381],\n",
       "       [ 0.00322071],\n",
       "       [ 0.87844156],\n",
       "       [ 0.04867697],\n",
       "       [ 0.01002646]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HIS TRAINING & TEST CODE 4 -- TEST STEP\n",
    "test1_values = test_data[0].split(\",\") \n",
    "print(test1_values[0])\n",
    "test1_input = (np.asfarray(test1_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "n.query(test1_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, back to my code -- with the bug fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/xferUbuntu/notebooks/make_your_own_neural_network\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mnist_test_10.csv', 'mnist_train_100.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"/mnt/xferUbuntu/notebooks/make_your_own_neural_network/mnist\")\n",
    "os.listdir(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_file = open(os.path.join(os.getcwd(), \"mnist_train_100.csv\"), 'r')\n",
    "training_data = training_file.readlines()\n",
    "training_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carolyn/anaconda/envs/notebk/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural net using the MNIST data, and 200 hidden nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inodes = 28*28 # number of input nodes = dimensions of input images\n",
    "hnodes = 200 # he starts by using 100 hidden nodes\n",
    "onodes = 10 # number of output nodes = 10 (1 per digit)\n",
    "\n",
    "training_list = []\n",
    "target_list = []\n",
    "lrate = 0.1\n",
    "nnet2 = NeuralNetwork(inodes, hnodes, onodes, lrate)\n",
    "\n",
    "for line in training_data:\n",
    "    all_values = line.split(',')\n",
    "    assert len(all_values) == 28*28+1\n",
    "    \n",
    "    # rescale the input values into the range [0.01, 1.0]\n",
    "    # you're avoiding the value 0 because the weights can't affect that value,\n",
    "    # but the value 1 is okay for input.\n",
    "    # note you do not need to reshape the array before using it for training...\n",
    "    # the neural net doesn't care whether it looks like an image to you!\n",
    "    inputs = ((np.asfarray(all_values[1:])/255.0)*0.99) + 0.01\n",
    "    assert len(inputs) == inodes\n",
    "    assert inputs.min() >0\n",
    "    \n",
    "    # all the non-target entries will be .01, the target entry will be .99\n",
    "    # otherwise you'll get large weights and a saturated network because you'll be trying \n",
    "    # to hit impossible values\n",
    "    targets = (np.zeros(onodes) + 0.01)\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "\n",
    "    # ===>>> now we train individually with every sample.\n",
    "    nnet2.train(inputs, targets)\n",
    "\n",
    "# NOTE: BEFORE I FOUND THIS BUG, I WAS TRAINING WITH EVERYTHING in one pass, \n",
    "# instead of iteratively, as below:\n",
    "# nnet2.train(training_list, target_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now test the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open and set up the training data. \n",
    "test_file = open(os.path.join(os.getcwd(), \"mnist_test_10.csv\"), 'r')\n",
    "test_data = test_file.readlines()\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = []\n",
    "test_target_list = []\n",
    "for line in test_data:\n",
    "    all_values = line.split(',')\n",
    "    \n",
    "    # rescale the input values into the range [0.01, 1.0]\n",
    "    # you're avoiding the value 0 because the weights can't affect that value,\n",
    "    # but the value 1 is okay for input.\n",
    "    # note you do not need to reshape the array before using it for training...\n",
    "    # the neural net doesn't care whether it looks like an image to you!\n",
    "    image_array = (np.asfarray(all_values[1:])/255.0*0.99) +0.01\n",
    "    \n",
    "    # rescale the output targets into the range [.01, .99]\n",
    "    # all the non-target entries will be .01, the target entry will be .99\n",
    "    # otherwise you'll get large weights and a saturated network because you'll be trying \n",
    "    # to hit impossible values (0, 1)\n",
    "    target_array = (np.zeros(onodes)+0.01)\n",
    "    target_array[int(all_values[0])]=0.99\n",
    "\n",
    "    # append the training sample\n",
    "    test_list.append(image_array)\n",
    "    test_target_list.append(target_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.25289692e-01],\n",
       "       [  1.61022093e-03],\n",
       "       [  1.52741171e-02],\n",
       "       [  4.12553006e-03],\n",
       "       [  7.30825650e-03],\n",
       "       [  9.56403536e-04],\n",
       "       [  3.81431887e-02],\n",
       "       [  1.95614992e-01],\n",
       "       [  2.98569361e-03],\n",
       "       [  7.32189739e-04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet2.query(test_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01,  0.01,  0.01,  0.01,  0.99,  0.01,  0.01,  0.01,  0.01,  0.01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03772522],\n",
       "       [ 0.00461422],\n",
       "       [ 0.06128937],\n",
       "       [ 0.01487877],\n",
       "       [ 0.91565653],\n",
       "       [ 0.00653104],\n",
       "       [ 0.01563727],\n",
       "       [ 0.45043642],\n",
       "       [ 0.0878436 ],\n",
       "       [ 0.00106009]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet2.query(test_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
